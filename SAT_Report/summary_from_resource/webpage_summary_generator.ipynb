{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "113e1905",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_openai import ChatOpenAI\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e8fa73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load .env environment variables\n",
    "load_dotenv()\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "569e3e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_llm():\n",
    "    provider = os.getenv(\"MODEL_PROVIDER\")\n",
    "    if provider == \"GROQ\":\n",
    "        print(1)\n",
    "        # Initialize the Groq LLM\n",
    "        llm = ChatGroq(\n",
    "            model= os.getenv(\"GROQ_MODEL\"),\n",
    "            api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    "            temperature=0.1,\n",
    "            max_tokens=5000,\n",
    "            top_p=0.95,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            stop=None,\n",
    "        )\n",
    "    elif provider == \"OPENAI\":\n",
    "        # Initialize the OpenAI LLM\n",
    "        llm = ChatOpenAI(\n",
    "            model= os.getenv(\"OPENAI_MODEL\"),\n",
    "            openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "            temperature=0.1,\n",
    "            max_tokens=5000,\n",
    "            top_p=0.95,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            stop=None,\n",
    "        )\n",
    "    return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd11563c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = initialize_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9823eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"\n",
    "You are an expert educational content summarizer. Given multiple URLs of educational webpages, read the content from each URL carefully and generate a comprehensive, clear summary suitable for a student preparing for an exam.\n",
    "\n",
    "Important: Your entire summary must be written in your own words with zero direct copying from any source - rewrite every concept using your own explanations and language.\n",
    "\n",
    "**Instructions:**\n",
    "1. Read and analyze the content from each provided URL\n",
    "2. Identify common themes, concepts, and techniques across all sources\n",
    "3. Synthesize the information into a cohesive summary that covers all important points\n",
    "4. If sources cover different aspects of the same topic, integrate them seamlessly\n",
    "5. If sources cover completely different topics, organize them into separate sections\n",
    "\n",
    "The summary should include:  \n",
    " - A brief overview of the topic(s) or skill(s) covered across all sources\n",
    " - The key concepts or techniques explained in the lessons, consolidated from all URLs\n",
    " - Actionable study tips to help the student understand and apply these concepts effectively\n",
    " - Types of exercises the student should practice based on these topics â€” describe them clearly\n",
    " - Common mistakes or pitfalls to avoid while applying the concepts\n",
    "\n",
    "Do not copy text verbatim from any source; rewrite all ideas in your own words. Keep the summary structured with headings or bullet points if appropriate, and ensure it is easy to understand.\n",
    "\n",
    "**URLs to analyze:**\n",
    "{URLS}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "610e23ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def template_generator(urls:list):\n",
    "\n",
    "    template_data = {\n",
    "        \"URLS\": urls\n",
    "    }\n",
    "\n",
    "    return PROMPT.format(**template_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cea5c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "links_resource = r\"C:\\Users\\Manideep S\\Downloads\\L@\\SAT Paid Report\\Users_data\\\\RohanByali\\\\Input_data.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "265cafc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(links_resource, 'r', encoding='utf-8') as json_file:\n",
    "    json_data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0206f1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rw_skills = json_data[\"report\"][\"sat_readiness_report\"][\"tabs\"][3][\"subjects\"][0][\"sections\"][0][\"section_details\"]\n",
    "math_skills = json_data[\"report\"][\"sat_readiness_report\"][\"tabs\"][3][\"subjects\"][1][\"sections\"][0][\"section_details\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b3f1cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "rw_skills_links_summaries = []\n",
    "for skill in rw_skills:\n",
    "    # rw_skills_links.append({skill[\"name\"]:skill[\"educational_resources\"]})\n",
    "    prompt_template = template_generator(skill[\"educational_resources\"])\n",
    "    response = llm.invoke(prompt_template)\n",
    "    content = response.content if hasattr(response, \"content\") else response\n",
    "    processed_skill = {\n",
    "        \"name\": skill[\"name\"],\n",
    "        \"link\": skill[\"educational_resources\"],\n",
    "        \"summary\": content\n",
    "    }\n",
    "    rw_skills_links_summaries.append(processed_skill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db2f8ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"rw_skills_links_summaries.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(rw_skills_links_summaries, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2a48798",
   "metadata": {},
   "outputs": [],
   "source": [
    "math_skills_links_summaries = []\n",
    "for skill in math_skills:\n",
    "    # rw_skills_links.append({skill[\"name\"]:skill[\"educational_resources\"]})\n",
    "    prompt_template = template_generator(skill[\"educational_resources\"])\n",
    "    response = llm.invoke(prompt_template)\n",
    "    content = response.content if hasattr(response, \"content\") else response\n",
    "    processed_skill = {\n",
    "        \"name\": skill[\"name\"],\n",
    "        \"link\": skill[\"educational_resources\"],\n",
    "        \"summary\": content\n",
    "    }\n",
    "    math_skills_links_summaries.append(processed_skill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef91e337",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"math_skills_links_summaries.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(math_skills_links_summaries, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60fb9f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files_path = r\"C:\\Users\\Manideep S\\Downloads\\L@\\SAT Paid Report\\Users_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c01a691d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "input_files = glob.glob(os.path.join(input_files_path, \"*\", \"Input_data.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9eecbda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\Manideep S\\\\Downloads\\\\L@\\\\SAT Paid Report\\\\Users_data\\\\Aarthi\\\\Input_data.json', 'C:\\\\Users\\\\Manideep S\\\\Downloads\\\\L@\\\\SAT Paid Report\\\\Users_data\\\\Abhinav\\\\Input_data.json', 'C:\\\\Users\\\\Manideep S\\\\Downloads\\\\L@\\\\SAT Paid Report\\\\Users_data\\\\Amrita\\\\Input_data.json', 'C:\\\\Users\\\\Manideep S\\\\Downloads\\\\L@\\\\SAT Paid Report\\\\Users_data\\\\Anirudh\\\\Input_data.json', 'C:\\\\Users\\\\Manideep S\\\\Downloads\\\\L@\\\\SAT Paid Report\\\\Users_data\\\\GouriPradeep\\\\Input_data.json', 'C:\\\\Users\\\\Manideep S\\\\Downloads\\\\L@\\\\SAT Paid Report\\\\Users_data\\\\GovindPotti\\\\Input_data.json', 'C:\\\\Users\\\\Manideep S\\\\Downloads\\\\L@\\\\SAT Paid Report\\\\Users_data\\\\Ishan\\\\Input_data.json', 'C:\\\\Users\\\\Manideep S\\\\Downloads\\\\L@\\\\SAT Paid Report\\\\Users_data\\\\IshanaPotti\\\\Input_data.json', 'C:\\\\Users\\\\Manideep S\\\\Downloads\\\\L@\\\\SAT Paid Report\\\\Users_data\\\\Jevinn\\\\Input_data.json', 'C:\\\\Users\\\\Manideep S\\\\Downloads\\\\L@\\\\SAT Paid Report\\\\Users_data\\\\Lakshmi\\\\Input_data.json', 'C:\\\\Users\\\\Manideep S\\\\Downloads\\\\L@\\\\SAT Paid Report\\\\Users_data\\\\Meenakshi\\\\Input_data.json', 'C:\\\\Users\\\\Manideep S\\\\Downloads\\\\L@\\\\SAT Paid Report\\\\Users_data\\\\RohanBharathwaj\\\\Input_data.json', 'C:\\\\Users\\\\Manideep S\\\\Downloads\\\\L@\\\\SAT Paid Report\\\\Users_data\\\\RohanByali\\\\Input_data.json', 'C:\\\\Users\\\\Manideep S\\\\Downloads\\\\L@\\\\SAT Paid Report\\\\Users_data\\\\SaiSaahas\\\\Input_data.json', 'C:\\\\Users\\\\Manideep S\\\\Downloads\\\\L@\\\\SAT Paid Report\\\\Users_data\\\\Tara\\\\Input_data.json', 'C:\\\\Users\\\\Manideep S\\\\Downloads\\\\L@\\\\SAT Paid Report\\\\Users_data\\\\Toni\\\\Input_data.json', 'C:\\\\Users\\\\Manideep S\\\\Downloads\\\\L@\\\\SAT Paid Report\\\\Users_data\\\\Vaishnavi\\\\Input_data.json', 'C:\\\\Users\\\\Manideep S\\\\Downloads\\\\L@\\\\SAT Paid Report\\\\Users_data\\\\Zoha\\\\Input_data.json']\n"
     ]
    }
   ],
   "source": [
    "print(input_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "033cf0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_path in input_files:\n",
    "    with open(file_path, 'r+', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "        # print(data[\"report\"][\"sat_readiness_report\"][\"tabs\"][3][\"subjects\"][0][\"sections\"][0][\"section_details\"])\n",
    "        # RW\n",
    "        for skill in rw_skills_links_summaries:\n",
    "            for data_skill in data[\"report\"][\"sat_readiness_report\"][\"tabs\"][3][\"subjects\"][0][\"sections\"][0][\"section_details\"]:\n",
    "                if data_skill[\"name\"] == skill[\"name\"]:\n",
    "                    data_skill[\"educational_resources\"] = []\n",
    "                    data_skill[\"educational_resources\"] = [\n",
    "                        {\n",
    "                            \"name\": skill[\"name\"],\n",
    "                            \"link\": skill[\"link\"],\n",
    "                            \"summary\": skill[\"summary\"]\n",
    "                        }\n",
    "                    ]\n",
    "\n",
    "        # MATH\n",
    "        for skill in math_skills_links_summaries:\n",
    "            for data_skill in data[\"report\"][\"sat_readiness_report\"][\"tabs\"][3][\"subjects\"][1][\"sections\"][0][\"section_details\"]:\n",
    "                if data_skill[\"name\"] == skill[\"name\"]:\n",
    "                    data_skill[\"educational_resources\"] = []\n",
    "                    data_skill[\"educational_resources\"] = [\n",
    "                        {\n",
    "                            \"name\": skill[\"name\"],\n",
    "                            \"link\": skill[\"link\"],\n",
    "                            \"summary\": skill[\"summary\"]\n",
    "                        }\n",
    "                    ]\n",
    "\n",
    "        f.seek(0)\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "        f.truncate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ce3376",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_array = {}\n",
    "for each_skill in key_value_array:\n",
    "    prompt_template = template_generator(each_skill[1])\n",
    "    response = llm.invoke(prompt_template)\n",
    "    content = response.content if hasattr(response, \"content\") else response\n",
    "    content_array[each_skill[0]] = content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7974255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(content_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c372ee84",
   "metadata": {},
   "outputs": [],
   "source": [
    "for summary in content_array:\n",
    "    with open(\"math_\"+summary+\"_summary.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(content_array[summary])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4eab406",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myLLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
