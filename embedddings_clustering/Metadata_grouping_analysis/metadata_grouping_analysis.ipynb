{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cb8605",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import text\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance, PointStruct\n",
    "from InstructorEmbedding import INSTRUCTOR\n",
    "import uuid\n",
    "import numpy as np  \n",
    "from sklearn.decomposition import PCA\n",
    "import umap\n",
    "import plotly.figure_factory as ff\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffb0509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65058227",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "DB_URL = \"postgresql://postgres:pgAdmin@localhost:5432/Dump\"\n",
    "COLLECTION_NAME = \"math_embeddings\"\n",
    "QDRANT_HOST = \"localhost\"\n",
    "QDRANT_PORT = 6333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155d1451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# engine = create_engine(DB_URL)\n",
    "# model = SentenceTransformer(\"BAAI/bge-m3\") \n",
    "\n",
    "# client = QdrantClient(host=QDRANT_HOST, port=QDRANT_PORT)\n",
    "\n",
    "engine = create_engine(DB_URL)\n",
    "model = SentenceTransformer('hkunlp/instructor-xl')\n",
    " \n",
    "client = QdrantClient(host=QDRANT_HOST, port=QDRANT_PORT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216c3604",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfb94b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_metadata():\n",
    "    metadata_list = []\n",
    "    scroll_offset = None\n",
    "\n",
    "    while True:\n",
    "        result = client.scroll(\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            with_vectors=False,\n",
    "            with_payload=True,  \n",
    "            offset=scroll_offset,\n",
    "            limit=100\n",
    "        )\n",
    "\n",
    "        points, scroll_offset = result\n",
    "\n",
    "        for point in points:\n",
    "            if point.payload:\n",
    "                metadata_list.append(point.payload)\n",
    "\n",
    "        if scroll_offset is None:\n",
    "            break \n",
    "\n",
    "    return metadata_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78a575a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "HIERARCHY_ORDER = [\"subject\", \"domain\", \"skill\", \"subskill\", \"difficulty\"]\n",
    "\n",
    "def get_parent_keys(label_key):\n",
    "    idx = HIERARCHY_ORDER.index(label_key)\n",
    "    return HIERARCHY_ORDER[:idx]\n",
    "\n",
    "def get_unique_metadata_groups(metadata_list, group_keys):\n",
    "    groups = set()\n",
    "    for meta in metadata_list:\n",
    "        key = tuple(meta[k] for k in group_keys)\n",
    "        groups.add(key)\n",
    "    return list(groups)\n",
    "\n",
    "def filter_metadata_by_group(metadata_list, group_keys, group_values):\n",
    "    return [m for m in metadata_list if all(m[k] == v for k, v in zip(group_keys, group_values))]\n",
    "\n",
    "def get_vectors_for_label_in_group(full_filter_query: str, label_key: str, label_value: str, top_k: int = 50):\n",
    "    query = f\"{full_filter_query} AND {label_key}:{label_value}\" if full_filter_query else f\"{label_key}:{label_value}\"\n",
    "    return semantic_search_and_get_vector(query, top_k)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba55d925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_vectors_and_metadata_as_dataframe(parent_keys, parent_values):\n",
    "    \"\"\"\n",
    "    Fetch vectors and their metadata from Qdrant, then return a DataFrame with the vector and metadata as columns.\n",
    "    \"\"\"\n",
    "    assert len(parent_keys) == len(parent_values), \"Keys and values must be of same length\"\n",
    "    \n",
    "    filter_conditions = [\n",
    "        {\"key\": k, \"match\": {\"value\": v}} for k, v in zip(parent_keys, parent_values)\n",
    "    ]\n",
    "\n",
    "    vector_metadata_list = []  \n",
    "    scroll_offset = None\n",
    "\n",
    "    while True:\n",
    "        result = client.scroll(\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            with_vectors=True,\n",
    "            with_payload=True,\n",
    "            offset=scroll_offset,\n",
    "            limit=100,\n",
    "            scroll_filter={\"must\": filter_conditions}  \n",
    "        )\n",
    "        points, scroll_offset = result\n",
    "\n",
    "        for point in points:\n",
    "            vector = point.vector\n",
    "            payload = point.payload\n",
    "\n",
    "            if vector is not None and payload is not None:\n",
    "                vector_metadata_list.append([vector, payload])\n",
    "\n",
    "        if scroll_offset is None:\n",
    "            break\n",
    "\n",
    "    vector_data = []\n",
    "    metadata_columns = []\n",
    "\n",
    "    for vector, metadata in vector_metadata_list:\n",
    "        flattened_metadata = {**metadata}\n",
    "\n",
    "        vector_data.append([vector] + list(flattened_metadata.values()))  \n",
    "\n",
    "\n",
    "        if not metadata_columns:\n",
    "            metadata_columns = [key for key in flattened_metadata.keys()]\n",
    "\n",
    "    num_vector_columns = len(vector_data[0])\n",
    "    \n",
    "    df = pd.DataFrame(vector_data, columns=[\"vector\"] + metadata_columns)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66530ca6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5660786e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def semantic_search_and_get_vector(user_query, top_k):\n",
    "    query_vector = model.encode(user_query).tolist()\n",
    "\n",
    "    search_result = client.search(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        query_vector=query_vector,\n",
    "        with_vectors=True,\n",
    "        with_payload=True,\n",
    "        limit=top_k\n",
    "    )\n",
    "\n",
    "    vector_data = []\n",
    "    metadata_columns = []\n",
    "\n",
    "    for res in search_result:\n",
    "        if res.vector is not None and res.payload is not None:\n",
    "            flattened_metadata = {**res.payload}\n",
    "            vector_data.append([res.vector] + list(flattened_metadata.values()))\n",
    "\n",
    "            if not metadata_columns:\n",
    "                metadata_columns = list(flattened_metadata.keys())\n",
    "\n",
    "    if not vector_data:\n",
    "        return pd.DataFrame(columns=[\"vector\"] + metadata_columns)\n",
    "\n",
    "    df = pd.DataFrame(vector_data, columns=[\"vector\"] + metadata_columns)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b581d3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sklearn.manifold import TSNE\n",
    "import os\n",
    "\n",
    "def semantic_cluster_and_plot_by_label(df, label_key, group, parent_keys):\n",
    "\n",
    "    labels = df[label_key].unique()\n",
    "    group_semantic_df = []\n",
    "\n",
    "    for each_label in labels:\n",
    "        filtered_df = df[df[label_key] == each_label]\n",
    "        group_name = \"PID-\" + \"-\".join(group) + f\"-{each_label}\"\n",
    "\n",
    "        semantic_df = semantic_search_and_get_vector(\n",
    "            user_query=group_name,\n",
    "            top_k=len(filtered_df)\n",
    "        )\n",
    "\n",
    "        semantic_df['semantic_label'] = group_name\n",
    "\n",
    "        # print(f\"Label: {each_label}, Rows: {len(semantic_df)}\")\n",
    "        # print(semantic_df.head(), '\\n')\n",
    "\n",
    "        group_semantic_df.append(semantic_df)\n",
    "\n",
    "    if not group_semantic_df:\n",
    "        print(\"No semantic data collected.\")\n",
    "        return None\n",
    "\n",
    "    full_df = pd.concat(group_semantic_df, ignore_index=True)\n",
    "    group_semantic_search_df = pd.concat(group_semantic_df, ignore_index=True)\n",
    "\n",
    "\n",
    "    if 'vector' not in full_df.columns:\n",
    "        print(\"Skipping: 'vector' column missing.\")\n",
    "        return None\n",
    "\n",
    "    vectors = full_df['vector'].tolist()\n",
    "    vector_array = np.array(vectors)\n",
    "\n",
    "    # pca = PCA(n_components=2)\n",
    "    # reduced = pca.fit_transform(vector_array)\n",
    "    n_neighbors = min(15, len(vector_array) - 1)\n",
    "    reducer = umap.UMAP(n_components=2, n_neighbors=n_neighbors, min_dist=0.1, spread=1.0)\n",
    "    reduced = reducer.fit_transform(vector_array)\n",
    "\n",
    "    full_df['x'] = reduced[:, 0]\n",
    "    full_df['y'] = reduced[:, 1]\n",
    "    full_df.insert(0, 'S.No', range(1, len(full_df) + 1))\n",
    "\n",
    "    group_name = \"__\".join([f\"{k}-{v}\" for k, v in zip(parent_keys, group)])\n",
    "    os.makedirs(\"semantic-graph-analysis\", exist_ok=True)\n",
    "\n",
    "    csv_path = f\"semantic-graph-analysis/{group_name}.csv\"\n",
    "    html_path = f\"semantic-graph-analysis/{group_name}.html\"\n",
    "\n",
    "    full_df.to_csv(csv_path, index=False)\n",
    "\n",
    "    fig = px.scatter(\n",
    "        full_df, x='x', y='y',\n",
    "        color='semantic_label',\n",
    "        hover_data=['x', 'y'] + [col for col in full_df.columns if col not in ['x', 'y', 'vector']],\n",
    "        title=f\"Semantic space for group: {group_name.replace('__', ' | ')}\"\n",
    "    )\n",
    "    fig.update_traces(marker=dict(size=8, line=dict(width=0.5, color='DarkSlateGrey')))\n",
    "    fig.update_layout(\n",
    "        width=900, height=700,\n",
    "        title_x=0.5,\n",
    "        legend_title_text='semantic_label',\n",
    "    )\n",
    "    fig.write_html(html_path)\n",
    "\n",
    "    # kmeans_clustering_using_label_count(df, group_name, label_key, isSemanticSearch=True)\n",
    "    # kmeans_clustering_using_label_count(df, group_name, 'semantic_label', isSemanticSearch=True)\n",
    "\n",
    "    # return fig.to_html(full_html=False, include_plotlyjs='cdn')\n",
    "\n",
    "    # Collect all HTML graph strings\n",
    "    html_parts = []\n",
    "\n",
    "    # # Call 1: regular label clustering\n",
    "    # html_parts.append(kmeans_clustering_using_label_count(group_semantic_search_df, group_name, label_key, isSemanticSearch=True))\n",
    "\n",
    "    # # Call 2: semantic label clustering\n",
    "    # html_parts.append(kmeans_clustering_using_label_count(group_semantic_search_df, group_name, 'semantic_label', isSemanticSearch=True))\n",
    "\n",
    "    # Assume there's a final `fig` created separately\n",
    "    html_parts.append(fig.to_html(full_html=False, include_plotlyjs='cdn'))\n",
    "\n",
    "    # Combine and return\n",
    "    return '\\n'.join(html_parts)\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499d016e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from kneed import KneeLocator\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "def kmeans_clustering_with_elbow_and_plot(df, group_name, label_key):\n",
    "    if 'vector' not in df.columns:\n",
    "        print(\"Skipping: 'vector' column missing.\")\n",
    "        return\n",
    "\n",
    "    vectors = np.array(df['vector'].tolist())\n",
    "\n",
    "    inertia = []\n",
    "    k_range = range(2, min(15, len(vectors)))  \n",
    "\n",
    "    for k in k_range:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42, n_init='auto')\n",
    "        kmeans.fit(vectors)\n",
    "        inertia.append(kmeans.inertia_)\n",
    "\n",
    "    knee = KneeLocator(k_range, inertia, curve='convex', direction='decreasing')\n",
    "    optimal_k = knee.knee or 2  \n",
    "\n",
    "    print(f\"Optimal number of clusters (K): {optimal_k}\")\n",
    "\n",
    "    final_kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init='auto')\n",
    "    df['cluster'] = final_kmeans.fit_predict(vectors)\n",
    "\n",
    "    elbow_fig = go.Figure()\n",
    "    elbow_fig.add_trace(go.Scatter(x=list(k_range), y=inertia, mode='lines+markers', name='Inertia'))\n",
    "    elbow_fig.add_vline(x=optimal_k, line_dash='dash', line_color='green', annotation_text=f\"K={optimal_k}\", annotation_position=\"top right\")\n",
    "    elbow_fig.update_layout(\n",
    "        title=\"Elbow Method For Optimal K\",\n",
    "        xaxis_title=\"Number of Clusters\",\n",
    "        yaxis_title=\"Inertia\",\n",
    "        width=600, height=400,\n",
    "    )\n",
    "\n",
    "    scatter_fig = px.scatter(\n",
    "        df, x='x', y='y',\n",
    "        color=df['cluster'].astype(str),\n",
    "        hover_data=['x', 'y'] + [col for col in df.columns if col not in ['x', 'y', 'vector']],\n",
    "        title=f\"KMeans Clustering for Group: {group_name}\"\n",
    "    )\n",
    "\n",
    "    scatter_fig.update_traces(marker=dict(size=8, line=dict(width=0.5, color='DarkSlateGrey')))\n",
    "    scatter_fig.update_layout(width=900, height=700, title_x=0.5,legend_title=\"Cluster\", coloraxis_showscale=False )\n",
    "\n",
    "    combined_html_path = f\"cluster-graph-analysis/{group_name}_kmeans.html\"\n",
    "    with open(combined_html_path, 'w') as f:\n",
    "        f.write(elbow_fig.to_html(full_html=False, include_plotlyjs='cdn'))\n",
    "        f.write(scatter_fig.to_html(full_html=False, include_plotlyjs=False))\n",
    "\n",
    "    updated_csv_path = f\"cluster-graph-analysis/{group_name}_kmeans.csv\"\n",
    "    df.to_csv(updated_csv_path, index=False)\n",
    "\n",
    "    return elbow_fig.to_html(full_html=False, include_plotlyjs=False) + \\\n",
    "       scatter_fig.to_html(full_html=False, include_plotlyjs=False) , updated_csv_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6e0684",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import os\n",
    "import umap\n",
    "\n",
    "def kmeans_clustering_using_label_count(df, group_name, label_key, isSemanticSearch=False):\n",
    "    if 'vector' not in df.columns:\n",
    "        print(\"Skipping: 'vector' column missing.\")\n",
    "        return\n",
    "\n",
    "    vectors = np.array(df['vector'].tolist())\n",
    "\n",
    "    # Calculate number of unique labels\n",
    "    unique_labels = df[label_key].dropna().unique()\n",
    "    k = len(unique_labels)\n",
    "    print(f\"Number of unique labels in '{label_key}' column: {k}\")\n",
    "\n",
    "    # Perform KMeans with k = number of unique labels\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init='auto')\n",
    "    df['cluster'] = kmeans.fit_predict(vectors)\n",
    "\n",
    "    # PCA for 2D projection\n",
    "    # pca = PCA(n_components=2)\n",
    "    # reduced = pca.fit_transform(vectors)\n",
    "    # n_neighbors = min(15, len(vectors) - 1)\n",
    "    # reducer = umap.UMAP(n_components=2, n_neighbors=n_neighbors, min_dist=0.1, spread=1.0)\n",
    "    # reduced = reducer.fit_transform(vectors)\n",
    "\n",
    "\n",
    "    # df['x_cluster'] = reduced[:, 0]\n",
    "    # df['y_cluster'] = reduced[:, 1]\n",
    "\n",
    "    # Scatter plot with clusters\n",
    "    scatter_fig = px.scatter(\n",
    "        df, x='x', y='y',\n",
    "        color=df['cluster'].astype(str),\n",
    "        hover_data=['x', 'y'] + [col for col in df.columns if col not in ['x', 'y', 'vector']],\n",
    "        title=f\"KMeans Clustering using Label Count ({label_key})\"\n",
    "    )\n",
    "\n",
    "    scatter_fig.update_traces(marker=dict(size=8, line=dict(width=0.5, color='DarkSlateGrey')))\n",
    "    scatter_fig.update_layout(width=900, height=700, title_x=0.5, legend_title=\"Cluster\", coloraxis_showscale=False)\n",
    "\n",
    "    # Save HTML and CSV\n",
    "    if(isSemanticSearch):\n",
    "        os.makedirs(\"semantic-cluster-graph-analysis\", exist_ok=True)\n",
    "        html_path = f\"semantic-cluster-graph-analysis/{group_name}_{label_key}_labelcount_kmeans.html\"\n",
    "        csv_path = f\"semantic-cluster-graph-analysis/{group_name}_{label_key}_labelcount_kmeans.csv\"\n",
    "    else:\n",
    "        os.makedirs(\"cluster-graph-analysis\", exist_ok=True)\n",
    "        html_path = f\"cluster-graph-analysis/{group_name}_{label_key}_labelcount_kmeans.html\"\n",
    "        csv_path = f\"cluster-graph-analysis/{group_name}_{label_key}_labelcount_kmeans.csv\"\n",
    "\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "    # os.makedirs(\"cluster-graph-analysis\", exist_ok=True)\n",
    "    # html_path = f\"cluster-graph-analysis/{group_name}_{label_key}_labelcount_kmeans.html\"\n",
    "    # df.to_csv(f\"cluster-graph-analysis/{group_name}_{label_key}_labelcount_kmeans.csv\", index=False)\n",
    "\n",
    "    with open(html_path, 'w') as f:\n",
    "        f.write(scatter_fig.to_html(full_html=True, include_plotlyjs='cdn'))\n",
    "\n",
    "    return scatter_fig.to_html(full_html=False, include_plotlyjs=False), csv_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d34782b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def append_visualization_section_to_global_html(\n",
    "    title: str,\n",
    "    metadata_html: str,\n",
    "    cluster_html: str,\n",
    "    lable_count_cluster_html: str,\n",
    "    summary_df: pd.DataFrame,\n",
    "    label_key: str,\n",
    "    output_path: str = \"reports/combined_analysis_report.html\"\n",
    "):\n",
    "    # Generate styled HTML from DataFrame\n",
    "    summary_df_html = summary_df.to_html(\n",
    "        index=False,\n",
    "        border=0,\n",
    "        classes=\"styled-table\",\n",
    "        justify=\"center\",\n",
    "        escape=False\n",
    "    )\n",
    "\n",
    "    section_html = f\"\"\"\n",
    "    <hr>\n",
    "    <h2 style=\"text-align:center; color:#2c3e50;\">{title}</h2>\n",
    "\n",
    "    <h3>1. Metadata Visualization</h3>\n",
    "    <p>\n",
    "        This plot is generated by retrieving vector embeddings from the Qdrant database \n",
    "        and filtering the data purely based on metadata fields. \n",
    "        The exact filters used are reflected in the section title above.\n",
    "        The high-dimensional vectors were reduced to 2D using UMAP to visualize how items cluster \n",
    "        based on their metadata.\n",
    "    </p>\n",
    "    {metadata_html}\n",
    "\n",
    "    <h3>2. KMeans Clustering</h3>\n",
    "    <p>\n",
    "        We applied KMeans clustering to the same metadata-filtered data to find natural groupings.\n",
    "    </p>\n",
    "    <h4>2.1 Clustering with Chosen K</h4>\n",
    "    <p>\n",
    "        In this plot, we used a fixed number of clusters (K) based on what we expected. \n",
    "        This helps us understand how items group when we already have an idea of how many clusters we want.\n",
    "    </p>\n",
    "    {lable_count_cluster_html}\n",
    "\n",
    "    <h3>3. {label_key.capitalize()} Accuracy Summary</h3>\n",
    "    <p>This table summarizes {label_key}-wise clustering accuracy and distribution based on metadata and clustering results.</p>\n",
    "    {summary_df_html}\n",
    "\n",
    "    <h4>2.2 Clustering with Elbow Method</h4>\n",
    "    <p>\n",
    "        Using the same metadata-filtered dataset as above, KMeans clustering was applied \n",
    "        to identify natural groupings within the data. \n",
    "        The Elbow method is used to estimate the optimal number of clusters. \n",
    "        This helps in understanding how well-defined the group structures are within the filtered metadata.\n",
    "    </p>\n",
    "    {cluster_html}\n",
    "    \"\"\"\n",
    "\n",
    "    styled_css = \"\"\"\n",
    "    <style>\n",
    "        body { font-family: Arial, sans-serif; margin: 20px; }\n",
    "        h2 { margin-top: 40px; }\n",
    "        hr { margin: 40px 0; }\n",
    "\n",
    "        .styled-table {\n",
    "            border-collapse: collapse;\n",
    "            margin: 20px 0;\n",
    "            font-size: 14px;\n",
    "            width: 50%;\n",
    "            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);\n",
    "        }\n",
    "        .styled-table thead tr {\n",
    "            background-color: #2c3e50;\n",
    "            color: #ffffff;\n",
    "            text-align: center;\n",
    "        }\n",
    "        .styled-table th,\n",
    "        .styled-table td {\n",
    "            padding: 10px 12px;\n",
    "            border: 1px solid #dddddd;\n",
    "            text-align: center;\n",
    "        }\n",
    "        .styled-table tbody tr:nth-child(even) {\n",
    "            background-color: #f3f3f3;\n",
    "        }\n",
    "    </style>\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    if not os.path.exists(output_path):\n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"\"\"\n",
    "            <html>\n",
    "            <head>\n",
    "                <title>Metadata Visualization Report</title>\n",
    "                <meta charset=\"utf-8\">\n",
    "                {styled_css}\n",
    "            </head>\n",
    "            <body>\n",
    "                <h1 style=\"text-align:center;\">Metadata Visualization Report</h1>\n",
    "                {section_html}\n",
    "            </body>\n",
    "            </html>\n",
    "            \"\"\")\n",
    "    else:\n",
    "        with open(output_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            existing_html = f.read()\n",
    "\n",
    "        updated_html = existing_html.replace(\"</body>\", f\"{section_html}</body>\")\n",
    "\n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(updated_html)\n",
    "\n",
    "    print(f\"Section appended to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72ca9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def append_semantic_search_section_to_html(\n",
    "    title: str,\n",
    "    semantic_html: str,\n",
    "    output_path: str = \"reports/semantic_search_report.html\"\n",
    "):\n",
    "    section_html = f\"\"\"\n",
    "    <hr>\n",
    "    <h2 style=\"text-align:center; color:#34495e;\">{title}</h2>\n",
    "\n",
    "    <h3>Semantic Search Visualization</h3>\n",
    "    <p>\n",
    "        This section shows the results of a semantic search where the query is vectorized and compared \n",
    "        against high-dimensional document embeddings stored in the Qdrant vector database.\n",
    "        The closest matches are projected into 2D space using dimensionality reduction (e.g., t-SNE or PCA or UMAP) \n",
    "        to help visualize how the semantically similar results are grouped.\n",
    "    </p>\n",
    "    {semantic_html}\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(output_path):\n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"\"\"\n",
    "            <html>\n",
    "            <head>\n",
    "                <title>Semantic Search Visualization Report</title>\n",
    "                <meta charset=\"utf-8\">\n",
    "                <style>\n",
    "                    body {{ font-family: Arial, sans-serif; margin: 20px; }}\n",
    "                    h2 {{ margin-top: 40px; }}\n",
    "                    hr {{ margin: 40px 0; }}\n",
    "                </style>\n",
    "            </head>\n",
    "            <body>\n",
    "                <h1 style=\"text-align:center;\">Semantic Search Visualization Report</h1>\n",
    "                {section_html}\n",
    "            </body>\n",
    "            </html>\n",
    "            \"\"\")\n",
    "    else:\n",
    "        with open(output_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            existing_html = f.read()\n",
    "\n",
    "        updated_html = existing_html.replace(\"</body>\", f\"{section_html}</body>\")\n",
    "\n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(updated_html)\n",
    "\n",
    "    print(f\"Semantic search section appended to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807412c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotcheckValidation_test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ac56be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def append_styled_df_to_html(styled_df, label_key: str, filter_query: str, save_path: str = \"reports/spot_check_validation_report.html\"):\n",
    "\n",
    "    title_html = f\"<h2>Cluster Validation for {label_key}: {filter_query}</h2>\\n\"\n",
    "    \n",
    "    table_html = styled_df.to_html(escape=False)\n",
    "    \n",
    "    content_to_append = title_html + table_html + \"<br><hr><br>\\n\"\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(\"<html><head><title>Cluster Validation Report</title></head><body>\\n\")\n",
    "\n",
    "    with open(save_path, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(content_to_append)\n",
    "\n",
    "    print(f\"Appended new section to {save_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301b74bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import plotly.express as px\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "\n",
    "def metadata_grouping_and_plot_auto_hierarchy(label_key: str):\n",
    "    parent_keys = get_parent_keys(label_key)\n",
    "    print(f\"Clustering on `{label_key}`, grouped by: {parent_keys}\")\n",
    "    \n",
    "    metadata_list = get_all_metadata()\n",
    "    groups = get_unique_metadata_groups(metadata_list, parent_keys)\n",
    "    group_dataframes = []\n",
    "\n",
    "\n",
    "    for idx, group in enumerate(groups, start=1):\n",
    "        filter_query_parts = [f\"{k}:{v}\" for k, v in zip(parent_keys, group)]\n",
    "        filter_query = \" AND \".join(filter_query_parts)\n",
    "\n",
    "        group_metadata = filter_metadata_by_group(metadata_list, parent_keys, group)\n",
    "        label_values = sorted(set(m[label_key] for m in group_metadata if label_key in m))\n",
    "\n",
    "        print(f\"Label values for group: {label_values}\")\n",
    "        print(f\"{idx}. Group: {filter_query} â€” Labels: {label_values}\")\n",
    "\n",
    "        df = get_vectors_and_metadata_as_dataframe(parent_keys, group)\n",
    "        print(f\"Fetched {len(df)} vectors and metadata for group: {filter_query}\")\n",
    "        semantic_df = df.copy(deep=True)\n",
    "        clustering_df = df.copy(deep=True)\n",
    "\n",
    "        group_dataframes.append(df)\n",
    "\n",
    "        semantic_html = semantic_cluster_and_plot_by_label(semantic_df, label_key, group, parent_keys)\n",
    "\n",
    "        if 'vector' not in df.columns:\n",
    "            print(\"Skipping: 'vector' column missing.\")\n",
    "            continue\n",
    "\n",
    "        vectors = df['vector'].tolist()\n",
    "        vector_array = np.array(vectors)\n",
    "\n",
    "        # pca = PCA(n_components=2)\n",
    "        # reduced = pca.fit_transform(vector_array)\n",
    "        n_neighbors = min(15, len(vector_array) - 1)\n",
    "        reducer = umap.UMAP(n_components=2, n_neighbors=n_neighbors, min_dist=0.1, spread=1.0)\n",
    "        reduced = reducer.fit_transform(vector_array)\n",
    "\n",
    "        df['x'] = reduced[:, 0]\n",
    "        df['y'] = reduced[:, 1]\n",
    "\n",
    "        fig = px.scatter(\n",
    "            df, x='x', y='y',\n",
    "            color=label_key,\n",
    "            hover_data=['x', 'y'] + [col for col in df.columns if col not in ['x', 'y', 'vector']],\n",
    "            title=f\"{label_key} distribution for group: {filter_query}\"\n",
    "        )\n",
    "\n",
    "        fig.update_traces(marker=dict(size=8, line=dict(width=0.5, color='DarkSlateGrey')))\n",
    "        fig.update_layout(\n",
    "            width=900, height=700,\n",
    "            title_x=0.5,\n",
    "            legend_title_text=label_key,\n",
    "        )\n",
    "\n",
    "        df.insert(0, 'S.No', range(1, len(df) + 1))\n",
    "\n",
    "        group_name = \"__\".join([f\"{k}-{v}\" for k, v in zip(parent_keys, group)])\n",
    "        csv_path = f\"metadata-graph-analysis/{group_name}.csv\"\n",
    "        html_path = f\"metadata-graph-analysis/{group_name}.html\"\n",
    "\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        fig.write_html(html_path)\n",
    "        metadata_html = fig.to_html(full_html=False, include_plotlyjs='cdn')\n",
    "        cluster_html, optimal_cluster_csv_path = kmeans_clustering_with_elbow_and_plot(df.copy(deep=True), group_name, label_key)\n",
    "        lable_count_cluster_html,lable_count_cluster_csv_path = kmeans_clustering_using_label_count(df.copy(deep=True), group_name, label_key)\n",
    "\n",
    "        spotcheckValidationDF, summary_df = spotcheckValidation_test.validateAndReturnDF(metadata_path = csv_path, labelled_KMeans_path= lable_count_cluster_csv_path, label_key=label_key, parent_key =parent_keys, parent_values = group)\n",
    "        append_styled_df_to_html(spotcheckValidationDF, label_key, filter_query)\n",
    "        # display(spotcheckValidationDF)\n",
    "\n",
    "        title = f\"Visualization for group: {filter_query}\"\n",
    "        append_visualization_section_to_global_html(\n",
    "            title=title,\n",
    "            metadata_html=metadata_html,\n",
    "            cluster_html=cluster_html,\n",
    "            summary_df=summary_df,\n",
    "            label_key=label_key,\n",
    "            lable_count_cluster_html=lable_count_cluster_html,\n",
    "        )\n",
    "        append_semantic_search_section_to_html(\n",
    "            title=title,\n",
    "            semantic_html=semantic_html,\n",
    "        )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716e950c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def prepare_graph_analysis_folders():\n",
    "    folders = [\n",
    "        \"metadata-graph-analysis\",\n",
    "        \"semantic-graph-analysis\",\n",
    "        \"cluster-graph-analysis\",\n",
    "        \"reports\",\n",
    "        \"semantic-cluster-graph-analysis\"\n",
    "    ]\n",
    "\n",
    "    for folder in folders:\n",
    "        try:\n",
    "            if os.path.exists(folder):\n",
    "                shutil.rmtree(folder)\n",
    "                print(f\"Deleted existing folder: {folder}\")\n",
    "            \n",
    "            os.makedirs(folder)\n",
    "            print(f\"Created new folder: {folder}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error handling folder '{folder}': {e}\")\n",
    "\n",
    "prepare_graph_analysis_folders()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a54c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata_grouping_and_plot_auto_hierarchy(\"subject\")\n",
    "metadata_grouping_and_plot_auto_hierarchy(\"domain\")\n",
    "metadata_grouping_and_plot_auto_hierarchy(\"skill\")\n",
    "metadata_grouping_and_plot_auto_hierarchy(\"subskill\")\n",
    "metadata_grouping_and_plot_auto_hierarchy(\"difficulty\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myLLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
