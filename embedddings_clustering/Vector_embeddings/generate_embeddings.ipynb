{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "441f86bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import text\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance, PointStruct\n",
    "from InstructorEmbedding import INSTRUCTOR\n",
    "import uuid\n",
    "import numpy as np  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ceabf9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "DB_URL = \"postgresql://postgres:pgAdmin@localhost:5432/SherpalDB_V2\"\n",
    "COLLECTION_NAME = \"math_v2_questiontext_reasoning_instructor_xl\"\n",
    "QDRANT_HOST = \"localhost\"\n",
    "QDRANT_PORT = 32770"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e47a369",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(DB_URL)\n",
    "# model = SentenceTransformer(\"BAAI/bge-m3\")  # Or use 'instructor-xl'\n",
    "model = SentenceTransformer('hkunlp/instructor-xl')\n",
    "\n",
    "client = QdrantClient(host=QDRANT_HOST, port=QDRANT_PORT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "feb43dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_questions():\n",
    "    query = text(\"\"\"\n",
    "        SELECT \n",
    "        q.id,\n",
    "        q.question_text,\n",
    "        q.passage,\n",
    "        q.question_type,\n",
    "        q.rationale,\n",
    "        q.options,\n",
    "        q.correct_answer,\n",
    "        q.hint,\n",
    "        q.prompt_id,\n",
    "        p.name AS prompt_name\n",
    "    FROM public.api_tempquestion q\n",
    "    JOIN public.api_tempprompt p ON q.prompt_id = p.id\n",
    "    FROM public.api_tempquestion q\n",
    "    JOIN public.api_tempprompt p ON q.prompt_id = p.id\n",
    "    WHERE p.name LIKE 'PID-M%'\n",
    "    order by p.name asc\n",
    "    \"\"\")\n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(query)\n",
    "        return [dict(row._mapping) for row in result]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c8cacb",
   "metadata": {},
   "source": [
    "Creating a Collection for instructor-XL model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39941686",
   "metadata": {},
   "outputs": [],
   "source": [
    "VECTOR_SIZE = model.get_sentence_embedding_dimension()\n",
    "\n",
    "def create_qdrant_collection():\n",
    "    if client.collection_exists(collection_name=COLLECTION_NAME):\n",
    "        print(f\"Collection '{COLLECTION_NAME}' already exists. Deleting it...\")\n",
    "        client.delete_collection(collection_name=COLLECTION_NAME)\n",
    "\n",
    "    print(f\"Creating collection '{COLLECTION_NAME}'...\")\n",
    "    client.create_collection(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        vectors_config=VectorParams(size=VECTOR_SIZE, distance=Distance.COSINE)\n",
    "    )\n",
    "    print(f\"Collection '{COLLECTION_NAME}' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e271907b",
   "metadata": {},
   "source": [
    "Creating a Collection for beg-m3 model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e4665b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# VECTOR_SIZE = model.get_sentence_embedding_dimension()\n",
    "\n",
    "# def create_qdrant_collection():\n",
    "#     test_vector = model.encode(\"test\")\n",
    "#     vector_size = len(test_vector) \n",
    "#     print(\"vector size =\", vector_size)\n",
    "#     client.recreate_collection(\n",
    "#         collection_name=COLLECTION_NAME,\n",
    "#         vectors_config=VectorParams(size=vector_size, distance=Distance.COSINE)\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8426404b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_prompt_name(prompt_name):\n",
    "    parts = prompt_name.split('-')\n",
    "    \n",
    "    if len(parts) < 6:\n",
    "        raise ValueError(\"Invalid prompt name format. Expected 6 parts separated by '-'.\")\n",
    "\n",
    "    return {\n",
    "        'subject': parts[1],\n",
    "        'domain': parts[2],\n",
    "        'skill': parts[3],\n",
    "        'subskill': parts[4],\n",
    "        'difficulty': parts[5]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef689a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import uuid\n",
    "import json\n",
    "from qdrant_client.models import PointStruct\n",
    "\n",
    "def extract_reasoning(rationale):\n",
    "    if isinstance(rationale, dict):\n",
    "        return rationale.get(\"reasoning\", \"\")\n",
    "    return \"\"\n",
    "\n",
    "def format_field(value):\n",
    "    if isinstance(value, dict):\n",
    "        return json.dumps(value, indent=2)\n",
    "    elif isinstance(value, list):\n",
    "        return \", \".join(map(str, value))\n",
    "    elif value is not None:\n",
    "        return str(value).strip()\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9c501f",
   "metadata": {},
   "source": [
    "Generating embeddings for instructor-XL model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9f04213",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_embeddings_and_upload(questions):\n",
    "    for q in tqdm(questions, desc=\"Processing Questions\", unit=\"question\"):\n",
    "        prompt_meta = parse_prompt_name(q['prompt_name'])\n",
    "\n",
    "        task_instruction = str(q[\"prompt_name\"]).strip() if q.get(\"prompt_name\") else \"\"\n",
    "\n",
    "        question_text = format_field(q.get(\"question_text\"))\n",
    "        reasoning_text = extract_reasoning(q.get(\"rationale\"))\n",
    "        input_text = \" | \".join(part for part in [question_text, reasoning_text] if part.strip())\n",
    "        # input_text = question_text\n",
    "\n",
    "        vector = model.encode([[task_instruction, input_text]])[0].tolist()\n",
    "\n",
    "\n",
    "        point = PointStruct(\n",
    "            id=str(uuid.uuid4()),\n",
    "            vector=vector,\n",
    "            payload={\"question_id\": q[\"id\"], \"prompt_name\": q[\"prompt_name\"], **prompt_meta}\n",
    "        )\n",
    "\n",
    "\n",
    "        # Debug Info\n",
    "        # print(\"\\n--- Embedding Info ---\")\n",
    "        # print(\"Instruction (metadata):\", task_instruction)\n",
    "        # print(\"Input text:\", input_text)\n",
    "        # print(\"Metadata payload:\", json.dumps(point.payload, indent=2))\n",
    "        # print(\"--- End ---\\n\")\n",
    "\n",
    "\n",
    "        client.upsert(collection_name=COLLECTION_NAME, points=[point])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb32b1f",
   "metadata": {},
   "source": [
    "Generating embeddings for beg-m3 model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c0beba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def generate_embeddings_and_upload(questions):\n",
    "#     for q in tqdm(questions, desc=\"Processing Questions\", unit=\"question\"):\n",
    "#         prompt_meta = parse_prompt_name(q['prompt_name'])\n",
    "        \n",
    "#         metadata_values = [str(q[\"prompt_name\"])] if q.get(\"prompt_name\") else []\n",
    "\n",
    "\n",
    "#         question_text = format_field(q.get(\"question_text\"))\n",
    "#         reasoning_text = extract_reasoning(q.get(\"rationale\"))\n",
    "\n",
    "#         input_text_parts = metadata_values + [question_text, reasoning_text]\n",
    "#         # input_text_parts = metadata_values + [question_text]\n",
    "\n",
    "#         input_text = \" | \".join(part for part in input_text_parts if part.strip())\n",
    "\n",
    "#         # Debug print\n",
    "#         # print(\"\\n--- Embedding Info ---\")\n",
    "#         # print(\"Metadata:\", json.dumps({\n",
    "#         #     \"question_id\": q[\"id\"],\n",
    "#         #     \"prompt_name\": q[\"prompt_name\"],\n",
    "#         #     **prompt_meta\n",
    "#         # }, indent=2))\n",
    "#         # print(\"Input text to embed:\", input_text)\n",
    "#         # print(\"--- End ---\\n\")\n",
    "\n",
    "#         # Uncomment these lines to enable embedding and uploading\n",
    "#         vector = model.encode(input_text).tolist()\n",
    "#         point = PointStruct(\n",
    "#             id=str(uuid.uuid4()),\n",
    "#             vector=vector,\n",
    "#             payload={ \"question_id\": q[\"id\"], \"prompt_name\": q[\"prompt_name\"], **prompt_meta }\n",
    "#         )\n",
    "#         client.upsert(collection_name=COLLECTION_NAME, points=[point])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "89ea4d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching questions...\n",
      "1814\n"
     ]
    }
   ],
   "source": [
    "print(\"Fetching questions...\")\n",
    "questions = fetch_questions()\n",
    "print(len(questions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d0c394f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating collection in Qdrant...\n",
      "Collection 'math_v2_questiontext_reasoning_instructor_xl' already exists. Deleting it...\n",
      "Creating collection 'math_v2_questiontext_reasoning_instructor_xl'...\n",
      "Collection 'math_v2_questiontext_reasoning_instructor_xl' created successfully.\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating collection in Qdrant...\")\n",
    "create_qdrant_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba82e827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings and uploading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Questions: 100%|██████████| 1814/1814 [1:27:28<00:00,  2.89s/question]\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating embeddings and uploading...\")\n",
    "generate_embeddings_and_upload(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46228f15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myLLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
